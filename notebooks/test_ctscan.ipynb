{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4da1722",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Imports\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "import os\n",
    "import pydicom\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import accuracy_score\n",
    "from collections import Counter\n",
    "from PIL import UnidentifiedImageError\n",
    "import cv2\n",
    "import numpy as np\n",
    "from skimage.metrics import structural_similarity as ssim\n",
    "from datetime import datetime\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f85dece1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# %%\n",
    "# 2. Paths\n",
    "base_dir = \"../data/ct_scans\"\n",
    "csv_path = os.path.join(base_dir, \"overview.csv\")\n",
    "tiff_dir = os.path.join(base_dir, \"tiff_images\")\n",
    "dcm_dir = os.path.join(base_dir, \"dicom_dir\")\n",
    "dcm_dir = os.path.join(base_dir, \"ctscan_png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e8f6cf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "# 3. Transform\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((128,128)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,))\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fec5abef",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CTDataset(Dataset):\n",
    "    def __init__(self, csv_file, tiff_dir, dcm_dir, transform=None, use_tiff=True):\n",
    "        self.data = pd.read_csv(csv_file)\n",
    "        self.tiff_dir = tiff_dir\n",
    "        self.dcm_dir = dcm_dir\n",
    "        self.transform = transform\n",
    "        self.use_tiff = use_tiff   # True → use TIFF images, False → use DICOM\n",
    "        # Map labels (you can adapt this mapping if your CSV has real labels)\n",
    "        self.label_map = {True: 1, False: 0}\n",
    "        # For now, we assign dummy labels (e.g., \"normal\") → you can update this later\n",
    "        # self.data[\"label\"] = \"normal\"\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.data.iloc[idx]\n",
    "        if self.use_tiff:\n",
    "            img_path = os.path.join(self.tiff_dir, row[\"tiff_name\"])\n",
    "            try:\n",
    "                img = Image.open(img_path).convert(\"RGB\")\n",
    "            except UnidentifiedImageError:\n",
    "                print(f\"Warning: Cannot open image {img_path}, skipping.\")\n",
    "                return self.__getitem__((idx + 1) % len(self.data))\n",
    "        else:\n",
    "            img_path = os.path.join(self.dcm_dir, row[\"dicom_name\"])\n",
    "            dcm = pydicom.dcmread(img_path)\n",
    "            img = Image.fromarray(dcm.pixel_array).convert(\"RGB\")\n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "        label = self.label_map[row[\"Contrast\"]]\n",
    "        return img, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b3c245a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Dataset & DataLoader\n",
    "dataset = CTDataset(csv_path, tiff_dir, dcm_dir, transform=transform, use_tiff=False)\n",
    "dataloader = DataLoader(dataset, batch_size=16, shuffle=True)\n",
    "\n",
    "print(\"Number of images:\", len(dataset))\n",
    "print(\"Sample batch:\")\n",
    "imgs, labels = next(iter(dataloader))\n",
    "print(imgs.shape, labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ced3e20",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleCNN(nn.Module):\n",
    "    def __init__(self, num_classes=3):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Conv2d(3, 16, 3, padding=1), nn.ReLU(), nn.MaxPool2d(2),\n",
    "            nn.Conv2d(16, 32, 3, padding=1), nn.ReLU(), nn.MaxPool2d(2),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(32*32*32, 128), nn.ReLU(),\n",
    "            nn.Linear(128, num_classes)\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "model = SimpleCNN(num_classes=3)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "063b8b4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7. Training Loop\n",
    "num_epochs = 100\n",
    "for epoch in range(num_epochs):\n",
    "    total_loss = 0\n",
    "    all_preds, all_labels = [], []\n",
    "    for imgs, labels in dataloader:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(imgs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "        preds = torch.argmax(outputs, dim=1)\n",
    "        all_preds.extend(preds.cpu().numpy())\n",
    "        all_labels.extend(labels.cpu().numpy())\n",
    "    acc = accuracy_score(all_labels, all_preds)\n",
    "    print(f\"Epoch {epoch+1}, Loss: {total_loss/len(dataloader):.4f}, Accuracy: {acc:.4f}\")\n",
    "\n",
    "# %%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11d60939",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = \"../backend/models/simple_cnn_ct.pth\"\n",
    "torch.save({'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'num_classes': 3}, model_path)\n",
    "print(f'Model saved to {model_path}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "97963c78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comparing scans:\n",
      " - Before (10:45:00): ../userImage/image1.png\n",
      " - After  (10:44:40): ../userImage/image2.png\n",
      "⚠️ Anomaly Detected between scans: Image Distortion\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "def detect_anomaly(img_path, prev_img_path, ssim_threshold=0.85):\n",
    "    \"\"\"\n",
    "    Compare current scan with previous one and detect anomalies.\n",
    "    Returns a string anomaly type if detected, else None.\n",
    "    \"\"\"\n",
    "    if prev_img_path is None:\n",
    "        return None  # No comparison for the first image\n",
    "    \n",
    "    # Load images (grayscale for simplicity)\n",
    "    img1 = cv2.imread(prev_img_path, cv2.IMREAD_GRAYSCALE)\n",
    "    img2 = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
    "    if img1 is None or img2 is None:\n",
    "        return \"Error: Could not load images\"\n",
    "    \n",
    "    # Resize to same shape\n",
    "    img1 = cv2.resize(img1, (256, 256))\n",
    "    img2 = cv2.resize(img2, (256, 256))\n",
    "    \n",
    "    # Compute SSIM\n",
    "    score, diff = ssim(img1, img2, full=True)\n",
    "    \n",
    "    if score < ssim_threshold:\n",
    "        # Simple heuristics for anomaly type\n",
    "        diff_mean = np.mean(diff)\n",
    "        if diff_mean < 0.3:\n",
    "            return \"Image Distortion\"\n",
    "        elif np.mean(cv2.absdiff(img1, img2)) > 25:\n",
    "            return \"Organ Shift\"\n",
    "        else:\n",
    "            return \"Instrument Misalignment\"\n",
    "    return None\n",
    "\n",
    "\n",
    "# --- Only Two Images ---\n",
    "before_img = \"../userImage/image1.png\"\n",
    "after_img = \"../userImage/image2.png\"\n",
    "\n",
    "# Get timestamps (from file modification times)\n",
    "before_time = datetime.fromtimestamp(os.path.getmtime(before_img)).strftime(\"%H:%M:%S\")\n",
    "after_time  = datetime.fromtimestamp(os.path.getmtime(after_img)).strftime(\"%H:%M:%S\")\n",
    "\n",
    "# Detect anomaly between before → after\n",
    "anomaly = detect_anomaly(after_img, before_img)\n",
    "\n",
    "print(f\"Comparing scans:\")\n",
    "print(f\" - Before ({before_time}): {before_img}\")\n",
    "print(f\" - After  ({after_time}): {after_img}\")\n",
    "\n",
    "if anomaly:\n",
    "    print(f\"⚠️ Anomaly Detected between scans: {anomaly}\")\n",
    "else:\n",
    "    print(\"✅ No anomaly detected between scans.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv-ai-tumor",
   "language": "python",
   "name": "venv-ai-tumor"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
